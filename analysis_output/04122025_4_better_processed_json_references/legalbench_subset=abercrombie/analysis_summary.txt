Benchmark 6/28: legalbench:subset=abercrombie
================================================================================

Models analyzed:
1. 01-ai_yi-34b
2. anthropic_claude-2.1
3. anthropic_claude-instant-1.2
4. openai_gpt-3.5-turbo-0613
5. writer_palmyra-x-v2
6. meta_llama-2-13b
7. tiiuae_falcon-7b
8. meta_llama-2-70b
9. cohere_command-light
10. openai_text-davinci-002
11. google_text-bison@001
12. mistralai_mixtral-8x7b-32kseqlen
13. openai_gpt-4-0613
14. cohere_command
15. AlephAlpha_luminous-supreme
16. writer_palmyra-x-v3
17. ai21_j2-jumbo
18. tiiuae_falcon-40b
19. ai21_j2-grande
20. AlephAlpha_luminous-base
21. meta_llama-2-7b
22. anthropic_claude-2.0
23. google_text-unicorn@001
24. mistralai_mistral-7b-v0.1
25. anthropic_claude-v1.3
26. AlephAlpha_luminous-extended
27. openai_gpt-4-1106-preview
28. meta_llama-65b
29. 01-ai_yi-6b
30. openai_text-davinci-003

=== Summary Statistics ===

+-------------+---------------+-----------------------+-------------------------------+---------------+
| Agreement   |   N Questions |   Avg Response Length |   Avg stats.quasi_exact_match | Std Range     |
+=============+===============+=======================+===============================+===============+
| High        |             0 |                   nan |                       nan     | nan - nan     |
+-------------+---------------+-----------------------+-------------------------------+---------------+
| Medium      |             3 |                     1 |                         0.333 | 0.183 - 0.254 |
+-------------+---------------+-----------------------+-------------------------------+---------------+
| Low         |            91 |                     1 |                         0.492 | 0.305 - 0.509 |
+-------------+---------------+-----------------------+-------------------------------+---------------+

=== Sample Questions and Responses ===

+-------------+---------------------------------------------+------------------------------------+-----------------------------------------------------------------+
| Agreement   | Question                                    | References                         | Model Responses (first 3)                                       |
+=============+=============================================+====================================+=================================================================+
| High        | No examples in this category                | N/A                                | N/A                                                             |
+-------------+---------------------------------------------+------------------------------------+-----------------------------------------------------------------+
| Medium      | Description: The mark "Microsoft" for small | Reference 1: suggestive (correct)  | Sample response 1 (stats.quasi_exact_match=0.000):  arbitrary   |
|             | computers.                                  |                                    | Sample response 2 (stats.quasi_exact_match=0.000): arbitrary    |
|             |                                             |                                    | Sample response 3 (stats.quasi_exact_match=0.000): fanciful     |
+-------------+---------------------------------------------+------------------------------------+-----------------------------------------------------------------+
| Low         | Description: The mark "Coastal Winery" for  | Reference 1: descriptive (correct) | Sample response 1 (stats.quasi_exact_match=1.000):  descriptive |
|             | varietal wines.                             |                                    | Sample response 2 (stats.quasi_exact_match=1.000): descriptive  |
|             |                                             |                                    | Sample response 3 (stats.quasi_exact_match=1.000): descriptive  |
+-------------+---------------------------------------------+------------------------------------+-----------------------------------------------------------------+